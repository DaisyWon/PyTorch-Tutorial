{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 201 Torch and Numpy\n",
    "\n",
    "View more, visit my tutorial page: https://mofanpy.com/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "\n",
    "Dependencies:\n",
    "* torch: 0.1.11\n",
    "* numpy\n",
    "\n",
    "Details about math operation in torch can be found in: http://pytorch.org/docs/torch.html#math-operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "numpy array: [[0 1 2]\n",
      " [3 4 5]] \n",
      "torch tensor: tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      "tensor to array: [[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "# convert numpy to tensor or vise versa\n",
    "np_data = np.arange(6).reshape((2, 3))\n",
    "torch_data = torch.from_numpy(np_data)\n",
    "tensor2array = torch_data.numpy()\n",
    "print(\n",
    "    '\\nnumpy array:', np_data,          # [[0 1 2], [3 4 5]]\n",
    "    '\\ntorch tensor:', torch_data,      #  0  1  2 \\n 3  4  5    [torch.LongTensor of size 2x3]\n",
    "    '\\ntensor to array:', tensor2array, # [[0 1 2], [3 4 5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "abs \n",
      "numpy:  [1 2 1 2] \n",
      "torch:  tensor([1., 2., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "# abs\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "print(\n",
    "    '\\nabs',\n",
    "    '\\nnumpy: ', np.abs(data),          # [1 2 1 2]\n",
    "    '\\ntorch: ', torch.abs(tensor)      # [1 2 1 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 1., 2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sin \n",
      "numpy:  [-0.84147098 -0.90929743  0.84147098  0.90929743] \n",
      "torch:  tensor([-0.8415, -0.9093,  0.8415,  0.9093])\n"
     ]
    }
   ],
   "source": [
    "# sin\n",
    "print(\n",
    "    '\\nsin',\n",
    "    '\\nnumpy: ', np.sin(data),      # [-0.84147098 -0.90929743  0.84147098  0.90929743]\n",
    "    '\\ntorch: ', torch.sin(tensor)  # [-0.8415 -0.9093  0.8415  0.9093]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2689,  0.1192,  0.7311,  0.8808])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3679,  0.1353,  2.7183,  7.3891])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean \n",
      "numpy:  0.0 \n",
      "torch:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# mean\n",
    "print(\n",
    "    '\\nmean',\n",
    "    '\\nnumpy: ', np.mean(data),         # 0.0\n",
    "    '\\ntorch: ', torch.mean(tensor)     # 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "matrix multiplication (matmul) \n",
      "numpy:  [[ 7 10]\n",
      " [15 22]] \n",
      "torch:  tensor([[ 7., 10.],\n",
      "        [15., 22.]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "data = [[1,2], [3,4]]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "# correct method\n",
    "print(\n",
    "    '\\nmatrix multiplication (matmul)',\n",
    "    '\\nnumpy: ', np.matmul(data, data),     # [[7, 10], [15, 22]]\n",
    "    '\\ntorch: ', torch.mm(tensor, tensor)   # [[7, 10], [15, 22]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy中，matrix1.dot(matrix2) 等价 np.matmul(matrix1, matrix2)\n",
    "#### pytorch中，tensor1.dot(tensor2)只允许一维计算内积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [15, 22]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(data)\n\u001b[1;32m      5\u001b[0m data\u001b[38;5;241m.\u001b[39mdot(data)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mmatrix multiplication (dot)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mnumpy: \u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m.\u001b[39mdot(data),        \u001b[38;5;66;03m# [[7, 10], [15, 22]]\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# NOT WORKING! Beware that torch.dot does not broadcast, only works for 1-dimensional tensor\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "# incorrect method\n",
    "data = [[1,2], [3,4]]\n",
    "data = np.array(data)\n",
    "tensor = torch.Tensor(data)\n",
    "data.dot(data)\n",
    "print(\n",
    "    '\\nmatrix multiplication (dot)',\n",
    "    '\\nnumpy: ', data.dot(data),        # [[7, 10], [15, 22]]\n",
    "    '\\ntorch: ', tensor.dot(tensor)    # NOT WORKING! Beware that torch.dot does not broadcast, only works for 1-dimensional tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "\n",
    "torch.dot(tensor1, tensor2) → float\n",
    "\n",
    "Computes the dot product (inner product) of two tensors. Both tensors are treated as 1-D vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  7.,  10.],\n",
       "        [ 15.,  22.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.mm(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逐个位置元素相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   4.],\n",
       "        [  9.,  16.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.Tensor([2, 3]), torch.Tensor([2, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 21, 31],\n",
       "        [21, 31, 41]], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[12, 22, 32],\n",
       "        [22, 32, 42]], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([[11,21,31],[21,31,41]],dtype=torch.int)\n",
    "# x1.shape # torch.Size([2, 3])\n",
    "x1\n",
    "\n",
    "\n",
    "x2 = torch.tensor([[12,22,32],[22,32,42]],dtype=torch.int)\n",
    "# x2.shape  # torch.Size([2, 3])\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcat(inputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mcat(inputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "inputs = [x1, x2]\n",
    "torch.cat(inputs, dim=0).shape\n",
    "torch.cat(inputs, dim=1).shape\n",
    "torch.cat(inputs, dim=2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.6240, 3.9728],\n",
       "        [2.2436, 1.6678],\n",
       "        [2.2064, 2.2010]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.1614, 2.2841],\n",
       "        [2.1946, 3.1991],\n",
       "        [1.3020, 2.0481]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = torch.ones(3, 2)\n",
    "n_data\n",
    "\n",
    "# 以下等价\n",
    "# 均值为2，方差为1的tensor\n",
    "x0 = torch.normal(2*n_data, 1)      # class0 x data (tensor), shape=(100, 2)\n",
    "x1 = torch.normal(2, 1, size=n_data.shape) \n",
    "x0\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2275,  1.7848, -0.1732,  1.1750,  1.5804],\n",
       "        [ 1.8737,  1.7338,  0.6046,  1.6957,  0.6215]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.0,1.0, 1.0, 1.0, 1.0],[2.0,2.0,2.0,2.0,2.0]])\n",
    "torch.normal(x, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = torch.ones(3, 2)\n",
    "n_data.dtype\n",
    "n_data = n_data.type(torch.FloatTensor)\n",
    "n_data.dtype\n",
    "n_data = n_data.type(torch.LongTensor)\n",
    "n_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  torch.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6652, 0.6652])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, prediction = torch.max(torch.tensor([[0.0900, 0.6652, 0.2447],\n",
    "        [0.0900, 0.2447, 0.6652]]), 1)\n",
    "_\n",
    "prediction\n",
    "prediction.data.numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.6652, 0.6652]),\n",
       "indices=tensor([1, 2]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2*3, 对3个取max\n",
    "torch.max(torch.tensor([[0.0900, 0.6652, 0.2447],\n",
    "        [0.0900, 0.2447, 0.6652]]), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.softmax(out) 不改变维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/hlff0j413bs7qvny_cknz7400000gn/T/ipykernel_2732/2184643305.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.6652, 0.2447],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "out = torch.tensor([[1.0,3.0, 2.0],[1.0,2.0, 3.0]])\n",
    "F.softmax(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unsqueeze, squeeze\n",
    "以下等价  \n",
    "纬度转变（5，）-> (5,1)      \n",
    "tensor1.unsqueeze(dim=1)     \n",
    "torch.unsqueeze(tensor1, dim=1) \n",
    "\n",
    "纬度转变（5，）-> (1,5)      \n",
    "tensor1.unsqueeze(dim=0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -0.5000,  0.0000,  0.5000,  1.0000]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -0.5000,  0.0000,  0.5000,  1.0000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000, -0.5000,  0.0000,  0.5000,  1.0000])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000],\n",
       "        [-0.5000],\n",
       "        [ 0.0000],\n",
       "        [ 0.5000],\n",
       "        [ 1.0000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000, -0.5000,  0.0000,  0.5000,  1.0000])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1702],\n",
       "        [0.9062],\n",
       "        [0.2094],\n",
       "        [0.4600],\n",
       "        [0.0204]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.linspace(-1, 1, 5) # （5,）\n",
    "a.shape\n",
    "b = torch.unsqueeze(a, dim=0) # (1,5)\n",
    "b\n",
    "b.squeeze()\n",
    "b = torch.unsqueeze(a, dim=1) # (5,1)\n",
    "b\n",
    "b.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.rand\n",
    "0到1之间的随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5236, 0.6239, 0.4030, 0.6044],\n",
       "        [0.3770, 0.8355, 0.4010, 0.6421],\n",
       "        [0.9987, 0.4850, 0.0314, 0.4333]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
